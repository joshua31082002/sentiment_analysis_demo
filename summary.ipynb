{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "word_lemmatizer = WordNetLemmatizer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(filename):\n",
    "    df = pd.read_csv(filename,encoding='latin-1',header=None)\n",
    "    df = df[[5,0]]\n",
    "    df.columns = ['statement','analysis']\n",
    "    df['index_col']=1\n",
    "    df['index_col'] = df['index_col'].cumsum()\n",
    "    df.dropna()\n",
    "    return df\n",
    "\n",
    "def feature_label_split(df):\n",
    "    X = df['statement']\n",
    "    y = df['analysis']\n",
    "    X = X.astype(str)\n",
    "    y = y.astype(int)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    emoji_dict = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "                    ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "                    ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', r':\\\\': 'annoyed', \n",
    "                    ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "                    '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "                    '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "                    ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
    "    \n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('<[^>]*>',' tag ',sentence)\n",
    "    sentence = re.sub(r'((http://)[^ ]*|(https://)[^ ]*|(www\\.)[^ ]*)', ' url ',sentence)\n",
    "    sentence = re.sub('@[^\\s]+>',' USER ',sentence)\n",
    "    sentence = re.sub('[^a-zA-Z0-9]',' ',sentence) \n",
    "    for emoji in emoji_dict.keys():\n",
    "        sentence = sentence.replace(emoji, \" EMOJI \"+emoji_dict[emoji])\n",
    "    sentence = re.sub(r\"(.)\\1\\1+\",r\"\\1\\1\",sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "def lemmatizer(sentence):\n",
    "    return ''.join([word_lemmatizer.lemmatize(word) for word in sentence])\n",
    "\n",
    "def stop_words_remover(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = ''.join(sentence)\n",
    "    stopwords = nlp.Defaults.stop_words\n",
    "    new_sent = ''\n",
    "    for word_token in sentence.split():\n",
    "        if word_token not in stopwords:\n",
    "            new_sent = new_sent + word_token + ' '\n",
    "    return new_sent\n",
    "\n",
    "class DataCleaner(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,X=None,y=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        X_ = X.copy()\n",
    "        for row in X_.iteritems():\n",
    "            row = preprocess(row)\n",
    "            row = stop_words_remover(row)\n",
    "            row = lemmatizer(row)\n",
    "        return X_\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "                        ngram_range=(1,2),\n",
    "                        max_features=500000,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pickle.load(open('picklefiles/X_train.pickle','rb'))\n",
    "X_train_tr = pickle.load(open(\"picklefiles/X_train_tr.pickle\",'rb'))\n",
    "y_train = pickle.load(open(\"picklefiles/y_train.pickle\",'rb'))\n",
    "pipe = pickle.load(open('picklefiles/pipe_fitted.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = data_loading(\"test140.csv\")\n",
    "df_test = df_test.loc[df_test['analysis']!=2]\n",
    "X_test, y_test = feature_label_split(df_test)\n",
    "X_test_tr =pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model,X,y):\n",
    "    y_predictions = model.predict(X)\n",
    "    ac_score = accuracy_score(y,y_predictions)\n",
    "    return ac_score\n",
    "\n",
    "def compute_accuracy1(model,X,y):\n",
    "    y_predictions = model.predict(X)\n",
    "    y = y.apply(lambda x:0 if x==0 else 1)\n",
    "    y.astype(int)\n",
    "    ac_score = accuracy_score(y,y_predictions)\n",
    "    return ac_score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearsvcCV = pickle.load(open('picklefiles/linearsvc_best_model.pickle','rb'))\n",
    "linearsvc = linearsvcCV.best_estimator_\n",
    "\n",
    "svcCV = pickle.load(open('picklefiles/svc_best_model.pickle','rb'))\n",
    "svcclf = svcCV.best_estimator_\n",
    "\n",
    "logregCV = pickle.load(open('picklefiles/logreg_best_model.pickle','rb'))\n",
    "logreg = logregCV.best_estimator_\n",
    "\n",
    "multinomialnbCV = pickle.load(open('picklefiles/multinomialnb_best_model.pickle','rb'))\n",
    "multinomialnb = multinomialnbCV.best_estimator_\n",
    "\n",
    "mvotingCV = pickle.load(open('picklefiles/voting_best_model.pickle','rb'))\n",
    "mvoting = mvotingCV.best_estimator_\n",
    "\n",
    "baggingCV = pickle.load(open('picklefiles/bagging_best_model.pickle','rb'))\n",
    "bagging = baggingCV\n",
    "\n",
    "rforestCV = pickle.load(open('picklefiles/randforest_best_model.pickle','rb'))\n",
    "rforest = rforestCV.best_estimator_\n",
    "\n",
    "adaboost = pickle.load(open('picklefiles/adaboost_model.pickle','rb'))\n",
    "\n",
    "xgboost = pickle.load(open('picklefiles/xgboost_model.pickle','rb'))\n",
    "\n",
    "gradientboost = pickle.load(open('picklefiles/gradientboost_model.pickle','rb'))\n",
    "\n",
    "mlpclf = pickle.load(open('picklefiles/mlpclf_model.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC: SVC(C=10.0, cache_size=5, kernel='sigmoid', max_iter=1000)\n",
      "Training set accuracy:  0.5995675\n",
      "Test set accuracy:  0.6016713091922006\n",
      "\n",
      "LinearSVC: LinearSVC(C=0.1)\n",
      "Training set accuracy:  0.858434375\n",
      "Test set accuracy:  0.8272980501392758\n",
      "\n",
      "LogisticRegressor: LogisticRegression(max_iter=1000, n_jobs=-1, warm_start=True)\n",
      "Training set accuracy:  0.8566475\n",
      "Test set accuracy:  0.83008356545961\n",
      "\n",
      "MultinomialNB: MultinomialNB(alpha=1)\n",
      "Training set accuracy:  0.8386875\n",
      "Test set accuracy:  0.8440111420612814\n",
      "\n",
      "VotingClassifier: VotingClassifier(estimators=[('lsvc', LinearSVC(C=0.1)),\n",
      "                             ('lr',\n",
      "                              LogisticRegression(max_iter=1000, n_jobs=-1,\n",
      "                                                 warm_start=True)),\n",
      "                             ('mnb', MultinomialNB(alpha=1)),\n",
      "                             ('dt',\n",
      "                              DecisionTreeClassifier(max_depth=23,\n",
      "                                                     min_samples_leaf=5,\n",
      "                                                     min_samples_split=4))],\n",
      "                 n_jobs=-1)\n",
      "Training set accuracy:  0.855020625\n",
      "Test set accuracy:  0.8245125348189415\n",
      "\n",
      "BaggingClassifier: BaggingClassifier(base_estimator=LinearSVC(C=0.1), n_jobs=-1)\n",
      "Training set accuracy:  0.85700875\n",
      "Test set accuracy:  0.8245125348189415\n",
      "\n",
      "RandomForestClassifier: RandomForestClassifier(max_depth=200, min_samples_leaf=2, min_samples_split=8,\n",
      "                       n_estimators=20, n_jobs=-1)\n",
      "Training set accuracy:  0.795239375\n",
      "Test set accuracy:  0.7604456824512534\n",
      "\n",
      "AdaBoostClassifier: AdaBoostClassifier(n_estimators=200)\n",
      "Training set accuracy:  0.7463475\n",
      "Test set accuracy:  0.7409470752089137\n",
      "\n",
      "XGBClassifier: XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.5, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=25, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=200,\n",
      "              n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n",
      "Training set accuracy:  0.895970625\n",
      "Test set accuracy:  0.8217270194986073\n",
      "\n",
      "GradientBoostingClassifier: GradientBoostingClassifier(learning_rate=0.5, max_depth=25, max_features='sqrt',\n",
      "                           n_estimators=200, tol=0.0012, warm_start=True)\n",
      "Training set accuracy:  0.84224\n",
      "Test set accuracy:  0.8105849582172702\n",
      "\n",
      "MLPClassifier: MLPClassifier(hidden_layer_sizes=(50, 100, 10), learning_rate_init=0.005,\n",
      "              verbose=True)\n",
      "Training set accuracy:  0.762021875\n",
      "Test set accuracy:  0.7966573816155988\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSVC:\",svcclf)\n",
    "print('Training set accuracy: ',compute_accuracy(svcclf,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(svcclf,X_test_tr,y_test))\n",
    "print(\"\\nLinearSVC:\",linearsvc)\n",
    "print('Training set accuracy: ',compute_accuracy(linearsvc,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(linearsvc,X_test_tr,y_test))\n",
    "print(\"\\nLogisticRegressor:\",logreg)\n",
    "print('Training set accuracy: ',compute_accuracy(logreg,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(logreg,X_test_tr,y_test))\n",
    "print(\"\\nMultinomialNB:\",multinomialnb)\n",
    "print('Training set accuracy: ',compute_accuracy(multinomialnb,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(multinomialnb,X_test_tr,y_test))\n",
    "print(\"\\nVotingClassifier:\",mvoting)\n",
    "print('Training set accuracy: ',compute_accuracy(mvoting,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(mvoting,X_test_tr,y_test))\n",
    "print(\"\\nBaggingClassifier:\",bagging)\n",
    "print('Training set accuracy: ',compute_accuracy(bagging,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(bagging,X_test_tr,y_test))\n",
    "print(\"\\nRandomForestClassifier:\",rforest)\n",
    "print('Training set accuracy: ',compute_accuracy(rforest,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(rforest,X_test_tr,y_test))\n",
    "print(\"\\nAdaBoostClassifier:\",adaboost)\n",
    "print('Training set accuracy: ',compute_accuracy(adaboost,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(adaboost,X_test_tr,y_test))\n",
    "print(\"\\nXGBClassifier:\",xgboost)\n",
    "print('Training set accuracy: ',compute_accuracy1(xgboost,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy1(xgboost,X_test_tr,y_test))\n",
    "print(\"\\nGradientBoostingClassifier:\",gradientboost)\n",
    "print('Training set accuracy: ',compute_accuracy1(gradientboost,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy1(gradientboost,X_test_tr,y_test))\n",
    "print(\"\\nMLPClassifier:\",mlpclf)\n",
    "print('Training set accuracy: ',compute_accuracy(mlpclf,X_train_tr,y_train))\n",
    "print('Test set accuracy: ',compute_accuracy(mlpclf,X_test_tr,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_on_input(input):\n",
    "    statements = pd.Series(input)\n",
    "    statements_tr = pipe.transform(statements)\n",
    "    predictions = xgboost.predict(statements_tr)\n",
    "    temp_dict = {'statement':statements,\n",
    "                 'sentiment prediction': predictions   \n",
    "                }\n",
    "    result = pd.DataFrame(temp_dict)\n",
    "    result['sentiment prediction'] = result['sentiment prediction'].apply(lambda x: 'Negative' if x==0 else 'Positive')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>sentiment prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can't connect front end and backend</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infant the legend</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he is an idiot</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To all our teachers and mentors, your contribu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement sentiment prediction\n",
       "0                Can't connect front end and backend             Negative\n",
       "1                                  infant the legend             Positive\n",
       "2                                     he is an idiot             Negative\n",
       "3  To all our teachers and mentors, your contribu...             Positive"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = str(input(\"Enter the sentecne\"))\n",
    "a = [\"Can't connect front end and backend\",\"infant the legend\",\"he is an idiot\",\"To all our teachers and mentors, your contribution to our society is priceless.\"]\n",
    "result_table = prediction_on_input(a)\n",
    "result_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55e1bd3b0b077e0bc98218d3177b556cf36523ce0b56978437ca49173cd0e5fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
